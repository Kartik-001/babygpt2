```markdown
# BabyGPT2

An endâ€‘toâ€‘end â€œChatGPTâ€‘styleâ€ demo:  
- **Train & explore** a miniature GPTâ€‘2 â€œBabyGPTâ€ in Colab  
- **Serve** the trained model via a FastAPI + Docker API  
- **Interact** through a Next.js web chat UI  

---

## ğŸš€ Repository Structure

```

baby gpt2/
â”œâ”€â”€ babygpt2/
â”‚   â””â”€â”€ baby gpt-2.ipynb             â† Notebook for training & experimentation
â”‚
â”œâ”€â”€ babygpt2-api/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                  â† FastAPI app (+ CORS & healthâ€‘check)
â”‚   â”‚   â”œâ”€â”€ model.py                 â† load model & `generate_response()`
â”‚   â”‚   â””â”€â”€ model\_architecture.py    â† GPT2Model definition
â”‚   â”‚
â”‚   â”œâ”€â”€ babygpt2\_model\_final.pt      â† Saved PyTorch model weights
â”‚   â”œâ”€â”€ Dockerfile                   â† Build instructions for the API
â”‚   â””â”€â”€ requirements.txt             â† fastapi, uvicorn, torch, tiktoken
â”‚
â”œâ”€â”€ babygpt2-web/
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ index.js                 â† Next.js chat UI (axios â†’ `/generate`)
â”‚   â”œâ”€â”€ package.json                 â† next, react, axios, etc.
â”‚   â””â”€â”€ â€¦                            â† other Next.js config (public/, styles/, etc.)
â”‚
â””â”€â”€ README.md                        â† You are here

````

---

## ğŸ“¦ Whatâ€™s Inside

1. **`babygpt2/`**  
   - A Colab notebook to **train** or fineâ€‘tune your BabyGPT model on a small dataset.

2. **`babygpt2-api/`**  
   - **Inference server** powered by FastAPI.  
   - **Tokenizes** inputs withâ€¯`tiktoken.get_encoding("gpt2")`.  
   - **Generates** text with your saved `babygpt2_model_final.pt`.  
   - **Dockerized** for easy deployment.

3. **`babygpt2-web/`**  
   - **Next.js** frontâ€‘end that renders a chat box.  
   - **Calls** your `/generate` API endpoint and displays responses.  
   - Ready to deploy on Vercel, Netlify, or any static host.

---

## ğŸ› ï¸ Quickstart

### 1. Run the API Locally

```bash
cd babygpt2-api
pip install -r requirements.txt
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
````

* **Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)
* **Healthâ€‘check**: [http://localhost:8000/](http://localhost:8000/)
* **Generate**: `POST /generate` with JSON

  ```json
  { "prompt": "Hello, world!", "max_new_tokens": 50 }
  ```

---

### 2. Dockerize & Deploy

```bash
cd babygpt2-api
# Build
docker build -t yourhubuser/babygpt2-api:latest .
# Run locally
docker run --rm -d -p 8000:8000 babygpt2-api:latest
# Push to Docker Hub
docker tag babygpt2-api:latest yourhubuser/babygpt2-api:latest
docker push yourhubuser/babygpt2-api:latest
```

Then connect `yourhubuser/babygpt2-api:latest` to **Render.com** (free Docker service) or any container host.

---

### 3. Run the Frontâ€‘End

```bash
cd babygpt2-web
npm install
npm run dev
```

Visit [http://localhost:3000](http://localhost:3000), type a prompt, and click **Generate** to see BabyGPTâ€™s reply.

To deploy, use Vercel:

```bash
cd babygpt2-web
vercel login
vercel --prod
```

---

## ğŸŒ Custom Domains & HTTPS

* **API**: add `api.yourdomain.com` in Render â†’ set CNAME â†’ autoâ€‘SSL
* **UI**: add `yourdomain.com` in Vercel â†’ set CNAME â†’ autoâ€‘SSL

---

## ğŸ¤ Contributing

1. Fork this repo
2. Create a branch: `git checkout -b feat/your-feature`
3. Commit & push: `git push origin feat/your-feature`
4. Open a Pull Request

---

## ğŸ“„ License

This project is released under the **MIT License**. Feel free to use, modify, and extend!

---
